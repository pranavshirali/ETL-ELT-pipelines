[2025-05-23T11:29:00.876+0530] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-05-23T11:29:00.884+0530] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: elt_sales_stream_transformation.transform_sales_stream manual__2025-05-23T05:58:55.182606+00:00 [queued]>
[2025-05-23T11:29:00.888+0530] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: elt_sales_stream_transformation.transform_sales_stream manual__2025-05-23T05:58:55.182606+00:00 [queued]>
[2025-05-23T11:29:00.889+0530] {taskinstance.py:2865} INFO - Starting attempt 1 of 1
[2025-05-23T11:29:00.900+0530] {taskinstance.py:2888} INFO - Executing <Task(SQLExecuteQueryOperator): transform_sales_stream> on 2025-05-23 05:58:55.182606+00:00
[2025-05-23T11:29:00.904+0530] {standard_task_runner.py:72} INFO - Started process 9109 to run task
[2025-05-23T11:29:00.907+0530] {standard_task_runner.py:104} INFO - Running: ['airflow', 'tasks', 'run', 'elt_sales_stream_transformation', 'transform_sales_stream', 'manual__2025-05-23T05:58:55.182606+00:00', '--job-id', '166', '--raw', '--subdir', 'DAGS_FOLDER/elt_transformation_dag.py', '--cfg-path', '/tmp/tmp32a3wti2']
[2025-05-23T11:29:00.909+0530] {standard_task_runner.py:105} INFO - Job 166: Subtask transform_sales_stream
[2025-05-23T11:29:00.953+0530] {task_command.py:467} INFO - Running <TaskInstance: elt_sales_stream_transformation.transform_sales_stream manual__2025-05-23T05:58:55.182606+00:00 [running]> on host Voldemort.
[2025-05-23T11:29:01.001+0530] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='elt_sales_stream_transformation' AIRFLOW_CTX_TASK_ID='transform_sales_stream' AIRFLOW_CTX_EXECUTION_DATE='2025-05-23T05:58:55.182606+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-05-23T05:58:55.182606+00:00'
[2025-05-23T11:29:01.001+0530] {taskinstance.py:731} INFO - ::endgroup::
[2025-05-23T11:29:01.012+0530] {sql.py:306} INFO - Executing: 
        CREATE OR REPLACE TABLE AIRFLOW_DB.PUBLIC.SALES_STREAM_TRANSFORMED AS
        SELECT
            REGION,
            COUNTRY,
            "ITEM TYPE",
            "SALES CHANNEL",
            "ORDER PRIORITY",
            "ORDER DATE",
            "ORDER ID",
            "SHIP DATE",
            "UNITS SOLD",
            "UNIT PRICE",
            "UNIT COST",
            "TOTAL REVENUE",
            "TOTAL COST",
            "TOTAL PROFIT",
            CASE
                WHEN "ORDER PRIORITY" = 'H' THEN 'High'
                WHEN "ORDER PRIORITY" = 'L' THEN 'Low'
                WHEN "ORDER PRIORITY" = 'M' THEN 'Medium'
                WHEN "ORDER PRIORITY" = 'C' THEN 'Cold'
                ELSE "ORDER PRIORITY"
            END AS "ORDER_PRIORITY_DESC",
            DATEDIFF(
                'day',
                COALESCE(
                  TRY_TO_DATE("ORDER DATE", 'M/D/YYYY'),
                  TRY_TO_DATE("ORDER DATE", 'MM/DD/YYYY'),
                  TRY_TO_DATE("ORDER DATE", 'YYYY-MM-DD')
                ),
                COALESCE(
                  TRY_TO_DATE("SHIP DATE", 'M/D/YYYY'),
                  TRY_TO_DATE("SHIP DATE", 'MM/DD/YYYY'),
                  TRY_TO_DATE("SHIP DATE", 'YYYY-MM-DD')
                )
            ) AS "SHIPMENT_LEAD_TIME"
        FROM AIRFLOW_DB.PUBLIC."SALES STREAM";
        
[2025-05-23T11:29:01.018+0530] {base.py:84} INFO - Retrieving connection 'snowflake_con'
[2025-05-23T11:29:01.033+0530] {base.py:84} INFO - Retrieving connection 'snowflake_con'
[2025-05-23T11:29:01.033+0530] {connection.py:486} INFO - Snowflake Connector for Python Version: 3.15.0, Python Version: 3.10.12, Platform: Linux-5.15.167.4-microsoft-standard-WSL2-x86_64-with-glibc2.35
[2025-05-23T11:29:01.034+0530] {connection.py:1391} INFO - Connecting to GLOBAL Snowflake domain
[2025-05-23T11:29:01.653+0530] {snowflake.py:521} INFO - Running statement: CREATE OR REPLACE TABLE AIRFLOW_DB.PUBLIC.SALES_STREAM_TRANSFORMED AS
        SELECT
            REGION,
            COUNTRY,
            "ITEM TYPE",
            "SALES CHANNEL",
            "ORDER PRIORITY",
            "ORDER DATE",
            "ORDER ID",
            "SHIP DATE",
            "UNITS SOLD",
            "UNIT PRICE",
            "UNIT COST",
            "TOTAL REVENUE",
            "TOTAL COST",
            "TOTAL PROFIT",
            CASE
                WHEN "ORDER PRIORITY" = 'H' THEN 'High'
                WHEN "ORDER PRIORITY" = 'L' THEN 'Low'
                WHEN "ORDER PRIORITY" = 'M' THEN 'Medium'
                WHEN "ORDER PRIORITY" = 'C' THEN 'Cold'
                ELSE "ORDER PRIORITY"
            END AS "ORDER_PRIORITY_DESC",
            DATEDIFF(
                'day',
                COALESCE(
                  TRY_TO_DATE("ORDER DATE", 'M/D/YYYY'),
                  TRY_TO_DATE("ORDER DATE", 'MM/DD/YYYY'),
                  TRY_TO_DATE("ORDER DATE", 'YYYY-MM-DD')
                ),
                COALESCE(
                  TRY_TO_DATE("SHIP DATE", 'M/D/YYYY'),
                  TRY_TO_DATE("SHIP DATE", 'MM/DD/YYYY'),
                  TRY_TO_DATE("SHIP DATE", 'YYYY-MM-DD')
                )
            ) AS "SHIPMENT_LEAD_TIME"
        FROM AIRFLOW_DB.PUBLIC."SALES STREAM";, parameters: None
[2025-05-23T11:29:01.653+0530] {sql.py:814} INFO - Running statement: CREATE OR REPLACE TABLE AIRFLOW_DB.PUBLIC.SALES_STREAM_TRANSFORMED AS
        SELECT
            REGION,
            COUNTRY,
            "ITEM TYPE",
            "SALES CHANNEL",
            "ORDER PRIORITY",
            "ORDER DATE",
            "ORDER ID",
            "SHIP DATE",
            "UNITS SOLD",
            "UNIT PRICE",
            "UNIT COST",
            "TOTAL REVENUE",
            "TOTAL COST",
            "TOTAL PROFIT",
            CASE
                WHEN "ORDER PRIORITY" = 'H' THEN 'High'
                WHEN "ORDER PRIORITY" = 'L' THEN 'Low'
                WHEN "ORDER PRIORITY" = 'M' THEN 'Medium'
                WHEN "ORDER PRIORITY" = 'C' THEN 'Cold'
                ELSE "ORDER PRIORITY"
            END AS "ORDER_PRIORITY_DESC",
            DATEDIFF(
                'day',
                COALESCE(
                  TRY_TO_DATE("ORDER DATE", 'M/D/YYYY'),
                  TRY_TO_DATE("ORDER DATE", 'MM/DD/YYYY'),
                  TRY_TO_DATE("ORDER DATE", 'YYYY-MM-DD')
                ),
                COALESCE(
                  TRY_TO_DATE("SHIP DATE", 'M/D/YYYY'),
                  TRY_TO_DATE("SHIP DATE", 'MM/DD/YYYY'),
                  TRY_TO_DATE("SHIP DATE", 'YYYY-MM-DD')
                )
            ) AS "SHIPMENT_LEAD_TIME"
        FROM AIRFLOW_DB.PUBLIC."SALES STREAM";, parameters: None
[2025-05-23T11:29:05.505+0530] {sql.py:823} INFO - Rows affected: 1
[2025-05-23T11:29:05.505+0530] {snowflake.py:534} INFO - Rows affected: 1
[2025-05-23T11:29:05.506+0530] {snowflake.py:535} INFO - Snowflake query id: 01bc88c7-3201-a521-000d-39de000870e6
[2025-05-23T11:29:05.735+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-05-23T11:29:05.736+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=elt_sales_stream_transformation, task_id=transform_sales_stream, run_id=manual__2025-05-23T05:58:55.182606+00:00, execution_date=20250523T055855, start_date=20250523T055900, end_date=20250523T055905
[2025-05-23T11:29:05.771+0530] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-05-23T11:29:05.780+0530] {taskinstance.py:3900} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-05-23T11:29:05.780+0530] {local_task_job_runner.py:245} INFO - ::endgroup::
